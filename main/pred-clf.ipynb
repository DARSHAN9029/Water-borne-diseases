{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bfa5159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "\n",
    "lbl_disease = joblib.load('label_encoder_disease.pkl')\n",
    "model = joblib.load('case_regressor.pkl')\n",
    "lbl_district = joblib.load('label_encoder_district.pkl')\n",
    "\n",
    "# Using pickle\n",
    "with open('label_encoder_disease.pkl', 'rb') as f:\n",
    "    lbl_disease = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17f508b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date district  cases  predicted_cases\n",
      "0 2023-01-07   Kamrup      6         6.173376\n",
      "1 2023-01-08   Kamrup      1         1.183913\n",
      "2 2023-01-08   Kamrup      3         3.272526\n",
      "3 2023-01-08   Kamrup     10         9.960131\n",
      "4 2023-01-09   Kamrup      1         1.409281\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# -------------------------\n",
    "# 1. Load models and encoders\n",
    "# -------------------------\n",
    "model = joblib.load('case_regressor.pkl')                # Regression model\n",
    "lbl_district = joblib.load('label_encoder_district.pkl') # District encoder\n",
    "\n",
    "# -------------------------\n",
    "# 2. Load new data\n",
    "# -------------------------\n",
    "df_new = pd.read_csv(r\"C:\\Users\\PINKY\\OneDrive\\Desktop\\SIH\\data\\new_data.csv\")  # Update this path\n",
    "\n",
    "# Ensure date column is in datetime format\n",
    "df_new['date'] = pd.to_datetime(df_new['date'])\n",
    "df_new = df_new.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# -------------------------\n",
    "# 3. Preprocess new data\n",
    "# -------------------------\n",
    "\n",
    "# Encode district as usual (assuming all districts are known)\n",
    "df_new['district_enc'] = lbl_district.transform(df_new['district'])\n",
    "\n",
    "\n",
    "# Create time-based features\n",
    "df_new['dayofyear'] = df_new['date'].dt.dayofyear\n",
    "df_new['month'] = df_new['date'].dt.month\n",
    "df_new['week'] = df_new['date'].dt.isocalendar().week.astype(int)\n",
    "df_new['weekday'] = df_new['date'].dt.weekday\n",
    "df_new['is_weekend'] = df_new['weekday'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Create lag and rolling features\n",
    "for lag in [1, 2, 3, 7, 14]:\n",
    "    df_new[f'lag_{lag}'] = df_new.groupby(['district'])['cases'].shift(lag)\n",
    "\n",
    "for window in [3, 7, 14]:\n",
    "    df_new[f'roll_mean_{window}'] = df_new.groupby(['district'])['cases'].shift(1).rolling(window).mean()\n",
    "    df_new[f'roll_std_{window}'] = df_new.groupby(['district'])['cases'].shift(1).rolling(window).std()\n",
    "\n",
    "df_new['cases_diff_1'] = df_new.groupby(['district'])['cases'].diff(1)\n",
    "\n",
    "# Drop rows where lag or rolling features are NaN\n",
    "df_new = df_new.dropna().reset_index(drop=True)\n",
    "\n",
    "# -------------------------\n",
    "# 4. Prepare feature columns\n",
    "# -------------------------\n",
    "env_cols = [\n",
    "    'turbidity_NTU','water_surface_temp_C','chlorophyll_a_mg_m3',\n",
    "    'NDWI','NDVI','EVI','SPM_mg_L',\n",
    "    'surface_reflectance_B3','surface_reflectance_B4','surface_reflectance_B5'\n",
    "]\n",
    "\n",
    "feature_cols = (\n",
    "    ['district_enc','dayofyear','month','week','weekday','is_weekend'] +\n",
    "    [f'lag_{l}' for l in [1,2,3,7,14]] +\n",
    "    [f'roll_mean_{w}' for w in [3,7,14]] +\n",
    "    [f'roll_std_{w}' for w in [3,7,14]] +\n",
    "    ['cases_diff_1'] + env_cols\n",
    ")\n",
    "\n",
    "X_new = df_new[feature_cols]\n",
    "\n",
    "# -------------------------\n",
    "# 5. Make predictions\n",
    "# -------------------------\n",
    "\n",
    "# Regression â€“ predict case count\n",
    "df_new['predicted_cases'] = model.predict(X_new)\n",
    "\n",
    "# -------------------------\n",
    "# 6. Display or save results\n",
    "# -------------------------\n",
    "print(df_new[['date','district','cases','predicted_cases']].head())\n",
    "\n",
    "# Optionally, save to file\n",
    "df_new.to_excel('predictions_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468c08ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sih",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
